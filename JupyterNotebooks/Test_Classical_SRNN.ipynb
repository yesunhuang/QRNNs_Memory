{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the classical SRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for testing the classical SRNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify setting for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "currentPath=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import matplotlib and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the classical SRNN and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify path for the notebooks\n",
    "currentPath=os.path.join(currentPath,'..')\n",
    "currentPath=os.path.join(currentPath,'src')\n",
    "os.chdir(currentPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataGenerator.HenonMapDataGen import HenonMapDataGen\n",
    "from ClassicalModels.ClassicalSRNNs import ClassicalSRNN\n",
    "from ClassicalModels.ClassicalSRNNs import SuportFunction\n",
    "from GradientFreeOptimizers.CostFunc import GradFreeMSELoss\n",
    "import GradientFreeOptimizers.Helpers as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath=os.path.join(currentPath,'..\\data\\HenonMap\\Test')\n",
    "filename='HenonMapTest1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap=HenonMapDataGen(savepath=savepath)\n",
    "hmap.read_from_CSV(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Info:\n",
      "----------------------------------------\n",
      "Data Size: 1000\n",
      "Data Interval: 1\n",
      "Data ParamA: 1.4, Data ParamB: 0.3\n",
      "Data Bound: -1.2\n",
      "Data HeavyMem: True\n",
      "Data Seed:\n",
      " [0.02825174685561237, 0.08827631523818379]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(hmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSetRatio=0.2\n",
    "numStep=5\n",
    "batchSize=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIter,testIter=hmap.get_data_iter(testSetRatio,numStep,batchSize,mask=0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 156\n",
      "X= tensor([[ 0.0283,  0.0883,  0.9976, -0.3667,  1.1110],\n",
      "        [-0.2932,  0.5535,  0.4831,  0.8393,  0.1588],\n",
      "        [-0.5704,  0.2684,  0.7280,  0.3385,  1.0580],\n",
      "        [ 1.0608, -0.4793,  0.9967, -0.5344,  0.8991]])\n",
      "Y= tensor([[ 0.0000,  0.9976, -0.3667,  1.1110, -0.8381],\n",
      "        [ 0.5535,  0.4831,  0.8393,  0.1588,  1.2165],\n",
      "        [ 0.2684,  0.7280,  0.3385,  1.0580, -0.4657],\n",
      "        [-0.4793,  0.9967, -0.5344,  0.8991, -0.2921]])\n"
     ]
    }
   ],
   "source": [
    "X,Y=next(iter(trainIter))\n",
    "print('Train Data Size:',len(trainIter))\n",
    "print('X=',torch.squeeze(X))\n",
    "print('Y=',torch.squeeze(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 36\n",
      "X= tensor([[ 0.6972,  0.4958,  0.8650,  0.1012,  1.2451],\n",
      "        [ 1.1484, -0.7807,  0.4913,  0.4279,  0.8911],\n",
      "        [ 0.3035,  1.1060, -0.6214,  0.7912, -0.0627],\n",
      "        [-0.5884,  0.8441, -0.1741,  1.2108, -1.1047]])\n",
      "Y= tensor([[ 0.6972,  0.4958,  0.8650,  0.1012,  1.2451],\n",
      "        [ 1.1484, -0.7807,  0.4913,  0.4279,  0.8911],\n",
      "        [ 0.3035,  1.1060, -0.6214,  0.7912, -0.0627],\n",
      "        [-0.5884,  0.8441, -0.1741,  1.2108, -1.1047]])\n"
     ]
    }
   ],
   "source": [
    "X,Y=next(iter(testIter))\n",
    "print('Train Data Size:',len(testIter))\n",
    "print('X=',torch.squeeze(X))\n",
    "print('Y=',torch.squeeze(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the SRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get neccesary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "srnnTest1Sup=SuportFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=lambda Xs:[torch.squeeze(x) for x in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_rnn_state=srnnTest1Sup.get_init_state_fun()\n",
    "get_params=srnnTest1Sup.get_get_params_fun()\n",
    "rnn=srnnTest1Sup.get_forward_fn_fun()\n",
    "predict_fun=srnnTest1Sup.get_predict_fun(outputTransoform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the SRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize=outputSize=1\n",
    "hiddenSize=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=ClassicalSRNN(inputSize,hiddenSize,outputSize,get_params,init_rnn_state,rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 1]), 1, torch.Size([4, 6]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=net.begin_state(batchSize)\n",
    "Y,newState=net(X,state)\n",
    "Y.shape, len(newState), newState[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preX= tensor([[ 0.0283],\n",
      "        [ 0.0883],\n",
      "        [ 0.9976],\n",
      "        [-0.3667],\n",
      "        [ 1.1110]])\n",
      "preY= [tensor([0.0283]), tensor([0.0883]), tensor([0.9976]), tensor([-0.3667]), tensor([1.1110]), tensor([-0.8381]), tensor([0.3500]), tensor([0.5771]), tensor([0.6387]), tensor([0.6019]), tensor([0.6844])]\n"
     ]
    }
   ],
   "source": [
    "preX,preY=hmap.data_as_tensor\n",
    "preX,preY=torch.unsqueeze(preX[:5],-1),torch.unsqueeze(preY[:10],-1)\n",
    "print('preX=',preX)\n",
    "preY=[y for y in torch.cat((preX[:2],preY[1:]),dim=0)]\n",
    "print('preY=',preY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YHat= [tensor(0.0283), tensor(0.0883), tensor(0.9976), tensor(-0.3667), tensor(1.1110), tensor(-0.0001), tensor(-3.6559e-06), tensor(3.7026e-08), tensor(-9.4360e-10), tensor(9.4382e-12)]\n"
     ]
    }
   ],
   "source": [
    "preX=torch.unsqueeze(preX,-1)\n",
    "YHat=predict_fun(preX,net,numPreds=5)\n",
    "print('YHat=',YHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, testIter,updater, num_epochs, loss,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"train for an epoch\"\"\"\n",
    "    animator = hp.Animator(xlabel='epoch', ylabel='Loss',\n",
    "                            legend=['train','test'], xlim=[10, num_epochs])\n",
    "    # prediction\n",
    "    predict = lambda prefix: predict_fun(prefix,net, numPreds=5)\n",
    "    # train and predict\n",
    "    for epoch in range(num_epochs):\n",
    "        trainLoss, speed = SuportFunction.train_epoch(\n",
    "            net, train_iter, loss, updater, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict(preX))\n",
    "            testLoss=SuportFunction.evaluate_accuracy(net, testIter, loss, use_random_iter)\n",
    "            animator.add(epoch + 1, [trainLoss,testLoss])\n",
    "    testLoss=SuportFunction.evaluate_accuracy(net, testIter, loss, use_random_iter)\n",
    "    print(f'testLoss {testLoss:.1f}, {speed:.1f} point/s')\n",
    "    print(predict(preX))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d86c190dfcadcdaa67edec4a1ea82702241987b5b1f320c920d3d4ca36fee5b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
